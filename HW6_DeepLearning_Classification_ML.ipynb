{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luke Schwenke\n",
    "### Assignment #6 - Image Classification\n",
    "### May 13, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as ki\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as k\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, Flatten\n",
    "from keras.layers import LSTM, Dense, Dropout, MaxPooling2D\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the \"ImageDataGenerator()\" class from keras.processing.image to build out an instance called \"train_datagen\" with the following parameters: \n",
    "\n",
    "* rescale = 1./255\n",
    "* shear_range = 0.2\n",
    "* zoom_range = 0.2\n",
    "* horizontal_flip = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then build your training set by using the method \".flow_from_directory()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = train_datagen.flow_from_directory(\n",
    "    './dataset_train',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (64, 64, 3)\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Image shape:\", train_datagen.image_shape)\n",
    "print(\"Number of classes:\", train_datagen.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Classifier Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of Sequential called \"classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.clear_session() # Clear previous session and reset (release GPU memory resources by resetting backend state)\n",
    "classifier = Sequential() # Instance for Linear sequence model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a Conv2D layer with the following parameters: \n",
    "* filters = 32\n",
    "* kernel_size = (3,3)\n",
    "* input_shape = image shape found in part 1\n",
    "* activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=32, \n",
    "                      kernel_size=(3, 3),\n",
    "                      input_shape=(64, 64, 3), \n",
    "                      activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a MaxPooling2D layer where pool_size = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add another Conv2D layer: \n",
    "* filters = 64\n",
    "* kernel_size = (3,3)\n",
    "* activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=32, \n",
    "                      kernel_size=(3, 3), \n",
    "                      activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a MaxPooling2D layer where pool_size = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a Dense layer\n",
    "* units = 128\n",
    "* activation = relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=128, \n",
    "                     activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a final Dense layer (this will output our probabilities):\n",
    "* units = # of classes\n",
    "* activation = softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=train_datagen.num_classes, \n",
    "                     activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile with the following: \n",
    "* optimize = adam\n",
    "* loss = categorical cross entropy\n",
    "* metric = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,604\n",
      "Trainable params: 813,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(optimizer=\"adam\", \n",
    "                   loss=\"categorical_crossentropy\", \n",
    "                   metrics=[\"acc\"])\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x11ddd734220>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use .fit() with the training set. For the first run, use the following parameters: \n",
    "* steps_per_epoch = 3\n",
    "* epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 1.2214 - acc: 0.4545\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.8163 - acc: 0.6932\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.4469 - acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "classifier_fit = classifier.fit(train_datagen, \n",
    "                                steps_per_epoch=3, \n",
    "                                epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deeplearning_classifier_saved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: deeplearning_classifier_saved\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "classifier.save('deeplearning_classifier_saved')\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Predict using the model built in step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "./dataset_test\\1022.png\n",
      "./dataset_test\\1053.png\n",
      "./dataset_test\\4011.png\n",
      "./dataset_test\\4053.png\n",
      "./dataset_test\\6023.png\n",
      "./dataset_test\\6051.png\n",
      "./dataset_test\\C014.png\n",
      "./dataset_test\\C033.png\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0], dtype=int64),\n",
       " array([1], dtype=int64),\n",
       " array([1], dtype=int64),\n",
       " array([2], dtype=int64),\n",
       " array([1], dtype=int64),\n",
       " array([1], dtype=int64),\n",
       " array([1], dtype=int64),\n",
       " array([3], dtype=int64)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('deeplearning_classifier_saved')\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# test data path\n",
    "img_dir = \"./dataset_test\" # Enter Directory of test set\n",
    "\n",
    "# iterate over each test image\n",
    "data_path = os.path.join(img_dir, '*g')\n",
    "files = glob.glob(data_path)\n",
    "\n",
    "# print the files in the dataset_test folder \n",
    "for f in files:\n",
    "    print(f)\n",
    "    \n",
    "# make a prediction and add to results \n",
    "data = []\n",
    "results = []\n",
    "for f1 in files:\n",
    "    img = image.load_img(f1, target_size = (64, 64))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    data.append(img)\n",
    "    result = model.predict(img)\n",
    "    r = np.argmax(result, axis=1)\n",
    "    results.append(r)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Accuracy\n",
    "* **Note**: To determine accuracy, you will need to check the labels given to each class in the training data and manually label your test data. This will require you to\n",
    "* Look into the training data(images) in the dataset_train folder, and then determine how a category was coded in keras using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category 1': 0, 'category 2': 1, 'category 3': 2, 'category 4': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check category labels in training_set\n",
    "train_datagen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look in the test data(images) in the dataset_test folder, and identify what category each images belongs to using images in the training set as references(there are only 8 test observations).\n",
    "Create a list to store the category/labels for the test data as the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = [0, 0, 2, 2, 1, 1, 3, 3] # Hand labelled from the test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predicted values to the actual values for the test set and calculate accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 1, 1, 1, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = [a for r in results for a in r]\n",
    "predicted # Extracted the prediction for each of the 8 arrays above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 1, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = [i for i, j in zip(actual_labels, predicted) if i == j]\n",
    "correct_predictions # Keep the pairwise combinations that are equal -- these are the correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 62.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = len(correct_predictions) / len(actual_labels) # Number of correct / Total\n",
    "print(f\"Model accuracy: {accuracy * 100}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this same process over a grid of combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_calculate(params):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(32, (3, 3), activation=\"relu\",input_shape=(64,64,3)))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    classifier.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(128, activation='relu'))\n",
    "    classifier.add(Dense(4, activation='softmax'))\n",
    "    classifier.compile(loss='categorical_crossentropy',\n",
    "                       optimizer='adam',\n",
    "                       metrics=[\"acc\"])\n",
    "    # Fit to the unique parameters in the grid\n",
    "    classifier.fit(train_datagen, \n",
    "                   steps_per_epoch=params[\"steps_per_epoch\"], \n",
    "                   epochs=params[\"epochs\"])\n",
    "    # Save this model off\n",
    "    classifier.save(params[\"model_name\"])\n",
    "    print(\"Saved model\")\n",
    "    \n",
    "    import os, glob\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    # returns a compiled model\n",
    "    # identical to the previous one\n",
    "    model = load_model(params[\"model_name\"])\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # test data path\n",
    "    img_dir = \"./dataset_test\"\n",
    "\n",
    "    # iterate over each test image\n",
    "    data_path = os.path.join(img_dir, '*g')\n",
    "    files = glob.glob(data_path)\n",
    "    \n",
    "    data = []\n",
    "    results = []\n",
    "    for f1 in files:\n",
    "        img = image.load_img(f1, target_size = (64, 64))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "        data.append(img)\n",
    "        result = model.predict(img)\n",
    "        r = np.argmax(result, axis=1)\n",
    "        results.append(r)\n",
    "        \n",
    "    test_label= [[0], [0], [2], [2], [1], [1], [3], [3]]\n",
    "    predicted = [a for b in results for a in b]\n",
    "    test_label == predicted\n",
    "    accuracy = len([a for a, b in zip(test_label, predicted) if a == b]) / len(test_label)\n",
    "    print(f\"Model accuracy: {accuracy * 100}%\\n\")\n",
    "    return(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\"steps_per_epoch\": 1, \"epochs\": 1, \"model_name\": \"model_1\"},\n",
    "              {\"steps_per_epoch\": 1, \"epochs\": 2, \"model_name\": \"model_2\"},\n",
    "              {\"steps_per_epoch\": 1, \"epochs\": 3, \"model_name\": \"model_3\"},\n",
    "              {\"steps_per_epoch\": 2, \"epochs\": 4, \"model_name\": \"model_4\"},\n",
    "              {\"steps_per_epoch\": 2, \"epochs\": 5, \"model_name\": \"model_5\"},\n",
    "              {\"steps_per_epoch\": 2, \"epochs\": 6, \"model_name\": \"model_6\"},\n",
    "              {\"steps_per_epoch\": 3, \"epochs\": 7, \"model_name\": \"model_7\"},\n",
    "              {\"steps_per_epoch\": 3, \"epochs\": 8, \"model_name\": \"model_8\"},\n",
    "              {\"steps_per_epoch\": 5, \"epochs\": 9, \"model_name\": \"model_9\"},\n",
    "              {\"steps_per_epoch\": 5, \"epochs\": 10, \"model_name\": \"model_10\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 665ms/step - loss: 1.3414 - acc: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 25.0%\n",
      "\n",
      "Accuracy for model_1: 0.25\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 1.3711 - acc: 0.3125\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 2.5417 - acc: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Model accuracy: 37.5%\n",
      "\n",
      "Accuracy for model_2: 0.375\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 1.4827 - acc: 0.3438\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 2.4656 - acc: 0.2812\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.4202 - acc: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 37.5%\n",
      "\n",
      "Accuracy for model_3: 0.375\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x0000011D8467C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_train_function.<locals>.train_function at 0x0000011D8467C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 139ms/step - loss: 1.6304 - acc: 0.3036\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 1.4972 - acc: 0.4375\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 0.9434 - acc: 0.7188\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.6967 - acc: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 75.0%\n",
      "\n",
      "Accuracy for model_4: 0.75\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 148ms/step - loss: 1.8790 - acc: 0.3929\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 1.6507 - acc: 0.2857\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.9866 - acc: 0.5893\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7587 - acc: 0.8214\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 0.5210 - acc: 0.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Model accuracy: 62.5%\n",
      "\n",
      "Accuracy for model_5: 0.625\n",
      "Epoch 1/6\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 1.4296 - acc: 0.5469\n",
      "Epoch 2/6\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.1801 - acc: 0.5179\n",
      "Epoch 3/6\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 0.6318 - acc: 0.8438\n",
      "Epoch 4/6\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.4721 - acc: 0.8438\n",
      "Epoch 5/6\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.2948 - acc: 0.9286\n",
      "Epoch 6/6\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.2187 - acc: 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Model accuracy: 87.5%\n",
      "\n",
      "Accuracy for model_6: 0.875\n",
      "Epoch 1/7\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 1.6003 - acc: 0.2159\n",
      "Epoch 2/7\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 1.1207 - acc: 0.7045\n",
      "Epoch 3/7\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 0.8203 - acc: 0.8182\n",
      "Epoch 4/7\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.4849 - acc: 0.9091\n",
      "Epoch 5/7\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.2763 - acc: 0.9205\n",
      "Epoch 6/7\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.2014 - acc: 0.9432\n",
      "Epoch 7/7\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 0.1660 - acc: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 75.0%\n",
      "\n",
      "Accuracy for model_7: 0.75\n",
      "Epoch 1/8\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 2.0662 - acc: 0.3409\n",
      "Epoch 2/8\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 1.1048 - acc: 0.4545\n",
      "Epoch 3/8\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.7577 - acc: 0.8295\n",
      "Epoch 4/8\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.4975 - acc: 0.8977\n",
      "Epoch 5/8\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.2788 - acc: 0.9432\n",
      "Epoch 6/8\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.1807 - acc: 0.9545\n",
      "Epoch 7/8\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.1754 - acc: 0.9545\n",
      "Epoch 8/8\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.1178 - acc: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Model accuracy: 75.0%\n",
      "\n",
      "Accuracy for model_8: 0.75\n",
      "Epoch 1/9\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.6095 - acc: 0.2955WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 45 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 45 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 301ms/step - loss: 1.6095 - acc: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 37.5%\n",
      "\n",
      "Accuracy for model_9: 0.375\n",
      "Epoch 1/10\n",
      "3/5 [=================>............] - ETA: 0s - loss: 1.7647 - acc: 0.2159WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 99ms/step - loss: 1.7647 - acc: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n",
      "Loaded model from disk\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Model accuracy: 75.0%\n",
      "\n",
      "Accuracy for model_10: 0.75\n",
      "Accuracies for all models: [0.25, 0.375, 0.375, 0.75, 0.625, 0.875, 0.75, 0.75, 0.375, 0.75]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for params in param_grid:\n",
    "    acc = fit_and_calculate(params)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Accuracy for {params['model_name']}: {acc}\")\n",
    "    \n",
    "# print out the final accuracies list\n",
    "print(\"Accuracies for all models:\", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steps_per_epoch</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>model_1</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>model_2</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>model_3</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>model_4</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>model_5</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>model_6</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>model_7</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>model_8</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>model_9</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>model_10</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   steps_per_epoch  epochs model_name  accuracy\n",
       "0                1       1    model_1     0.250\n",
       "1                1       2    model_2     0.375\n",
       "2                1       3    model_3     0.375\n",
       "3                2       4    model_4     0.750\n",
       "4                2       5    model_5     0.625\n",
       "5                2       6    model_6     0.875\n",
       "6                3       7    model_7     0.750\n",
       "7                3       8    model_8     0.750\n",
       "8                5       9    model_9     0.375\n",
       "9                5      10   model_10     0.750"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(param_grid).assign(accuracy=accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Discuss the effect of the following on accuracy and loss (train & test):** \n",
    "* **Increasing the steps_per_epoch**: this refers to the number of times the model updates weights within one epic. Increasing this value results in more weight updates (more opportunities to learn from the data). Increasing this value will generally improve the training accuracy and reduce the training loss. However, it might lead to overfitting if the model is learning too much from the training data without being able to generalize well to unseen data. The impact on test accuracy and loss depends on whether the model generalizes well to unseen data. If the model is overfitting due to a large number of steps_per_epoch, the test accuracy might not improve or could even decrease, while the test loss might increase. On the other hand, if the model is still able to generalize well, then increasing the steps_per_epoch could lead to better test accuracy and lower test loss.\n",
    "\n",
    "\n",
    "* **Increasing the number of epochs**: this refers to the number of times the model iterates over the entire dataset. Increasing the value means the model will have more opportunities to learn from the whole dataset. As the number of epochs increases, the training accuracy will generally improve, and the training loss will decrease. This happens because the model is learning from the data over more iterations. However, there is a risk of overfitting if the number of epochs is too high, as the model may learn too much from the training data and fail to generalize to unseen data. The impact of increasing the number of epochs on test accuracy and loss depends on the model's ability to generalize to unseen data. If the model overfits due to too many epochs, the test accuracy might not improve or could even decrease, and the test loss might increase. However, if the model can generalize well, then increasing the number of epochs could lead to better test accuracy and lower test loss, up to a certain point. Beyond that point, the improvements will likely plateau, and further increasing the number of epochs might not have a significant impact.\n",
    "\n",
    "**2 - Name two uses of zero padding in CNN**\n",
    "\n",
    "* **Preserving spatial dimensions:** In a CNN, as the input passes through convolutional and pooling layers, the spatial dimensions (width and height) of the input tend to shrink. This reduction can sometimes result in very small feature maps, especially in deeper layers, which can limit the network's ability to learn complex and hierarchical features. By applying zero padding before convolution, the spatial dimensions are preserved, allowing the network to retain more information from the input and potentially learn more complex features. This is particularly useful when designing deep CNN architectures.\n",
    "\n",
    "\n",
    "* **Controlling the field of view:** Zero padding can be used to control the receptive field or the field of view of the convolutional filters. With zero padding, the filters can slide over the edges and corners of the input, allowing the network to learn features from these regions. Without padding, the filters would only focus on the central parts of the input, potentially missing important information present at the edges and corners. By adjusting the amount of zero padding, the designer can control the degree to which the filters cover the input and thus influence the network's ability to learn features from different regions of the input.\n",
    "\n",
    "**3 - What is the use of a 1 x 1 kernel in CNN**\n",
    "\n",
    "* **Dimensionality reduction:** Reduces the number of channels while preserving spatial dimensions.\n",
    "* **Increasing non-linearity:** Introduces additional non-linearity when followed by an activation function.\n",
    "* **Feature map fusion:** Combines or fuses information from different channels.\n",
    "* **Parameter efficiency:** Requires fewer parameters compared to larger kernel sizes, making it more computationally efficient.\n",
    "\n",
    "**4 - What are the advantages of a CNN over a fully connected DNN for this image classification problem?**\n",
    "\n",
    "* **Local feature extraction:** CNNs capture local patterns and hierarchically learn complex features.\n",
    "* **Parameter efficiency:** CNNs have fewer trainable parameters due to shared weights in convolutional layers.\n",
    "* **Translation invariance:** CNNs can recognize features regardless of their location in the image.\n",
    "* **Scale and rotation invariance:** CNNs, combined with pooling layers, can learn features at different scales and rotations.\n",
    "* **Exploiting spatial structure:** CNNs preserve and exploit spatial information, while fully connected DNNs treat input as flattened vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
